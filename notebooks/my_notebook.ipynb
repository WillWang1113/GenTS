{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import einops\n",
    "from src.layers.flow import get_mask, MaskedLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32,10,2)\n",
    "x_hat = torch.randn(32,10,2)\n",
    "\n",
    "mse_loss = torch.nn.functional.mse_loss(x_hat, x) * 10 * 2\n",
    "sum_loss = torch.nn.functional.mse_loss(x_hat, x, reduction='sum') / 32\n",
    "print(mse_loss)\n",
    "print(sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum()/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum(dim=tuple(range(1, x.ndim))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "res = np.load('/home/user/data2/ICML_rebuttal/savings/uncond/etth2_24_S/KoVAEorig/cond_None_dtm_True_syn.npy')\n",
    "# res = np.load('/home/user/data/ICML_rebuttal/savings/uncond/etth2_24_S/KoVAE_orig/cond_None_dtm_True_syn.npy')\n",
    "start = np.random.randint(0, len(res))\n",
    "_ = plt.plot(res[start, :, :].squeeze().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/user/workspaces/THU-timeseries/ETT-small/ETTh2.csv', index_col=0)\n",
    "# df.values.shape\n",
    "start = np.random.randint(0, len(df)-24)\n",
    "_ = plt.plot(df.values[start:start+24, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional, Literal\n",
    "from lightning import LightningModule\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def _condition_shape_check(n_sample, condition, cond_type):\n",
    "    assert n_sample >=1\n",
    "    if cond_type is None:\n",
    "    \n",
    "        if condition.shape[0] == 1:\n",
    "            condition = condition.repeat(\n",
    "                n_sample, *[1 for _ in range(len(condition.shape) - 1)]\n",
    "            )\n",
    "        elif condition.shape[0] == n_sample:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The batch size of the given condition should be the same as n_sample or just 1.\"\n",
    "            )\n",
    " \n",
    "    return condition\n",
    "\n",
    "\n",
    "class BaseModel(ABC, LightningModule):\n",
    "    \"\"\"Base class for generative models in PyTorch Lightning\"\"\"\n",
    "    ALLOW_CONDITION = ...\n",
    "    \n",
    "    def __init__(self, seq_len, seq_dim, condition, lr, **kwargs):\n",
    "        super().__init__()\n",
    "        if condition not in self.ALLOW_CONDITION:\n",
    "            raise ValueError(f\"Condition '{condition}' not allowed. Choose from {self.ALLOW_CONDITION}\")\n",
    "    \n",
    "    @torch.no_grad()  # wrap with torch.no_grad()\n",
    "    def sample(self, n_sample: int = 1, condition=None, **kwargs):\n",
    "        \"\"\"Generate samples from the generative model\"\"\"\n",
    "        condition = _condition_shape_check(n_sample, condition, self.condition)\n",
    "        self.eval()\n",
    "        return self._sample_impl(n_sample, condition, **kwargs)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _sample_impl(self, n_sample: int = 1, condition=None, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"Actual implementation of the sampling process\"\"\"\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    \"\"\"AAAAAAA\n",
    "\n",
    "    Args:\n",
    "        BaseModel (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    ALLOW_CONDITION = [None, 'predict']\n",
    "    def __init__(self, seq_len, seq_dim, condition, lr, **kwargs):\n",
    "        \"\"\"aaaaaaa\n",
    "\n",
    "        Args:\n",
    "            seq_len (_type_): _description_\n",
    "            seq_dim (_type_): _description_\n",
    "            condition (_type_): _description_\n",
    "            lr (_type_): _description_\n",
    "        \"\"\"\n",
    "        super().__init__(seq_len, seq_dim, condition, lr, **kwargs)\n",
    "    \n",
    "    def _sample_impl(self, n_sample = 1, condition=None, **kwargs):\n",
    "        return super()._sample_impl(n_sample, condition, **kwargs)\n",
    "\n",
    "MyModel\n",
    "model = MyModel(24, 1, 'impute', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "total_seq_len = 64\n",
    "num_samples = 200\n",
    "t = torch.linspace(0, 4 * torch.pi, total_seq_len).float()\n",
    "curves = []\n",
    "labels = []\n",
    "for _ in range(num_samples):\n",
    "    a = torch.rand(1).item() * 0.5  # Initial radius\n",
    "    b = torch.rand(1).item() * 0.2  # Growth rate\n",
    "\n",
    "    direction = torch.randint(0, 2, (1,)).item()  # 0=clockwise, 1=ccw\n",
    "\n",
    "    r = a + b * t\n",
    "    if direction == 0:\n",
    "        x = r * torch.cos(t)\n",
    "        y = r * torch.sin(t)\n",
    "    else:\n",
    "        x = -r * torch.cos(t)\n",
    "        y = r * torch.sin(t)\n",
    "\n",
    "    x += torch.randn_like(x) * 0.01\n",
    "    y += torch.randn_like(y) * 0.01\n",
    "\n",
    "    curve = torch.stack([x, y], dim=1)\n",
    "    curves.append(curve)\n",
    "    labels.append(direction)\n",
    "data, class_cond = torch.stack(curves), torch.tensor(labels).unsqueeze(-1)\n",
    "print(data.shape, class_cond.shape)\n",
    "\n",
    "class_cond[1,...,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "\n",
    "n_fft = 200\n",
    "hop_length = 10\n",
    "data = torch.randn(32, 64, 5)\n",
    "hop_length = 8\n",
    "print((data.shape[1]) // hop_length + 1)\n",
    "data = torch.permute(\n",
    "    data, (0, 2, 1)\n",
    ")  # we permute to match requirements of torchaudio.transforms.Spectrogram\n",
    "spec = T.Spectrogram(n_fft=15, hop_length=hop_length, center=True, power=None).to(data.device)\n",
    "transformed_data = spec(data)\n",
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sine_data_generation(no, seq_len, dim, freq_scale=1):\n",
    "\n",
    "    \"\"\"Sine data generation.\n",
    "  \n",
    "    Args:\n",
    "    \n",
    "    - no: the number of samples\n",
    "    - seq_len: sequence length of the time-series\n",
    "    - dim: feature dimensions\n",
    "    \n",
    "    Returns:\n",
    "    - data: generated data\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialize the output\n",
    "    data = list()\n",
    "\n",
    "    # Generate sine data\n",
    "    for i in range(no):      \n",
    "        # Initialize each time-series\n",
    "        temp = list()\n",
    "        # For each feature\n",
    "        for k in range(dim):\n",
    "            # Randomly drawn frequency and phase\n",
    "            freq = np.random.uniform(0.05, 0.4)            \n",
    "            phase = np.random.uniform(0, 1.5)\n",
    "                \n",
    "            # Generate sine signal based on the drawn frequency and phase\n",
    "            temp_data = [np.sin(freq * j + phase) for j in range(seq_len)] \n",
    "            temp.append(temp_data)\n",
    "            \n",
    "        # Align row/column\n",
    "        temp = np.transpose(np.asarray(temp))        \n",
    "        # Normalize to [0,1]\n",
    "        temp = (temp + 1)*0.5\n",
    "        # Stack the generated data\n",
    "        data.append(temp)\n",
    "                    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.flow.fourierflow._fourier import DFT, reconstruct_DFT\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "t = np.linspace(0, 6, 65)\n",
    "k = int(len(t) / 2) + 1\n",
    "\n",
    "x = np.sin(t) + np.random.randn(*t.shape) * 0.1\n",
    "\n",
    "x = x.reshape(-1, len(t))\n",
    "x = torch.from_numpy(x)\n",
    "m = DFT(x.shape[1])\n",
    "z, log_pz, log_jacob = m(x)\n",
    "z = torch.complex(z[:, 0, :], z[:, 1, :])\n",
    "print(\"FF implement\")\n",
    "print(z.shape)\n",
    "print(z)\n",
    "\n",
    "print(\"torch.fft.rfft implement\")\n",
    "x_torch_fft = torch.fft.rfft(x) / len(t)\n",
    "print(x_torch_fft.shape)\n",
    "x_torch_fft = x_torch_fft.flip(dims=[1]).conj().type_as(z)\n",
    "print(x_torch_fft.shape)\n",
    "print(x_torch_fft)\n",
    "torch.testing.assert_close(x_torch_fft, z)\n",
    "\n",
    "# x_torch_fft = np.fft.fft(x)\n",
    "# x_torch_fft = np.fft.fftshift(x_torch_fft)\n",
    "# print(x_torch_fft.shape)\n",
    "# print(x_torch_fft)\n",
    "\n",
    "# x_torch = torch.complex(x_numpy[:,0,:], x_numpy[:,1,:])\n",
    "# print(x_torch.shape)\n",
    "# x_irfft = torch.fft.irfft(x_torch, dim=1)\n",
    "# x_irfft.shape\n",
    "\n",
    "# x_numpy_r = reconstruct_DFT(x_numpy[0, :, :], component=\"real\").detach().numpy()\n",
    "\n",
    "# x_numpy_i = reconstruct_DFT(x_numpy[0, :, :], component=\"imag\").detach().numpy()\n",
    "# print(x_numpy_r.shape)\n",
    "# print(x_numpy_i.shape)\n",
    "# np.real(np.fft.ifft(np.fft.ifftshift(x_numpy_r + 1j * x_numpy_i))).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.model.flow.temporalflow._backbones import TempFlowTrainingNetwork\n",
    "\n",
    "x = torch.randn(1, 7, 3)\n",
    "obs_x = torch.randn(1, 14, 3)\n",
    "\n",
    "m = TempFlowTrainingNetwork(\n",
    "    input_size=x.shape[-1],\n",
    "    num_layers=1,\n",
    "    num_cells=3,\n",
    "    cell_type=\"GRU\",\n",
    "    context_length=obs_x.shape[1],\n",
    "    history_length=14,\n",
    "    prediction_length=x.shape[1],\n",
    "    dropout_rate=0.1,\n",
    "    lags_seq=[1],\n",
    "    target_dim=x.shape[-1],\n",
    "    conditioning_length=200,\n",
    "    flow_type='MAF',\n",
    "    n_blocks=1,\n",
    "    hidden_size=64,\n",
    "    n_hidden=64,\n",
    "    dequantize=False\n",
    ")\n",
    "\n",
    "distr_args = m.distr_args(x)\n",
    "m.flow.log_prob(x, distr_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 2])\n",
      "torch.Size([32, 10, 2])\n",
      "torch.Size([32, 9, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchcde import linear_interpolation_coeffs, natural_cubic_coeffs\n",
    "\n",
    "x = torch.randn(32, 10, 2)\n",
    "x[11,3,0] = float('nan')\n",
    "x[1,6,1] = float('nan')\n",
    "x[3,1,0] = float('nan')\n",
    "\n",
    "print(x.shape)\n",
    "print(linear_interpolation_coeffs(x).shape)\n",
    "print(natural_cubic_coeffs(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(100, 24, 7)\n",
    "X = [np.hstack((0, data[k][:, 0])) for k in range(len(data))]\n",
    "X = np.array(X)\n",
    "X.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
