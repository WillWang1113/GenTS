{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import einops\n",
    "from src.layers.flow import get_mask, MaskedLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32,10,2)\n",
    "x_hat = torch.randn(32,10,2)\n",
    "\n",
    "mse_loss = torch.nn.functional.mse_loss(x_hat, x) * 10 * 2\n",
    "sum_loss = torch.nn.functional.mse_loss(x_hat, x, reduction='sum') / 32\n",
    "print(mse_loss)\n",
    "print(sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum()/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum(dim=tuple(range(1, x.ndim))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "res = np.load('/home/user/data2/ICML_rebuttal/savings/uncond/etth2_24_S/KoVAEorig/cond_None_dtm_True_syn.npy')\n",
    "# res = np.load('/home/user/data/ICML_rebuttal/savings/uncond/etth2_24_S/KoVAE_orig/cond_None_dtm_True_syn.npy')\n",
    "start = np.random.randint(0, len(res))\n",
    "_ = plt.plot(res[start, :, :].squeeze().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/user/workspaces/THU-timeseries/ETT-small/ETTh2.csv', index_col=0)\n",
    "# df.values.shape\n",
    "start = np.random.randint(0, len(df)-24)\n",
    "_ = plt.plot(df.values[start:start+24, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional, Literal\n",
    "from lightning import LightningModule\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def _condition_shape_check(n_sample, condition, cond_type):\n",
    "    assert n_sample >=1\n",
    "    if cond_type is None:\n",
    "    \n",
    "        if condition.shape[0] == 1:\n",
    "            condition = condition.repeat(\n",
    "                n_sample, *[1 for _ in range(len(condition.shape) - 1)]\n",
    "            )\n",
    "        elif condition.shape[0] == n_sample:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The batch size of the given condition should be the same as n_sample or just 1.\"\n",
    "            )\n",
    " \n",
    "    return condition\n",
    "\n",
    "\n",
    "class BaseModel(ABC, LightningModule):\n",
    "    \"\"\"Base class for generative models in PyTorch Lightning\"\"\"\n",
    "    ALLOW_CONDITION = ...\n",
    "    \n",
    "    def __init__(self, seq_len, seq_dim, condition, lr, **kwargs):\n",
    "        super().__init__()\n",
    "        if condition not in self.ALLOW_CONDITION:\n",
    "            raise ValueError(f\"Condition '{condition}' not allowed. Choose from {self.ALLOW_CONDITION}\")\n",
    "    \n",
    "    @torch.no_grad()  # wrap with torch.no_grad()\n",
    "    def sample(self, n_sample: int = 1, condition=None, **kwargs):\n",
    "        \"\"\"Generate samples from the generative model\"\"\"\n",
    "        condition = _condition_shape_check(n_sample, condition, self.condition)\n",
    "        self.eval()\n",
    "        return self._sample_impl(n_sample, condition, **kwargs)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _sample_impl(self, n_sample: int = 1, condition=None, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"Actual implementation of the sampling process\"\"\"\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    \"\"\"AAAAAAA\n",
    "\n",
    "    Args:\n",
    "        BaseModel (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    ALLOW_CONDITION = [None, 'predict']\n",
    "    def __init__(self, seq_len, seq_dim, condition, lr, **kwargs):\n",
    "        \"\"\"aaaaaaa\n",
    "\n",
    "        Args:\n",
    "            seq_len (_type_): _description_\n",
    "            seq_dim (_type_): _description_\n",
    "            condition (_type_): _description_\n",
    "            lr (_type_): _description_\n",
    "        \"\"\"\n",
    "        super().__init__(seq_len, seq_dim, condition, lr, **kwargs)\n",
    "    \n",
    "    def _sample_impl(self, n_sample = 1, condition=None, **kwargs):\n",
    "        return super()._sample_impl(n_sample, condition, **kwargs)\n",
    "\n",
    "MyModel\n",
    "model = MyModel(24, 1, 'impute', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "total_seq_len = 64\n",
    "num_samples = 200\n",
    "t = torch.linspace(0, 4 * torch.pi, total_seq_len).float()\n",
    "curves = []\n",
    "labels = []\n",
    "for _ in range(num_samples):\n",
    "    a = torch.rand(1).item() * 0.5  # Initial radius\n",
    "    b = torch.rand(1).item() * 0.2  # Growth rate\n",
    "\n",
    "    direction = torch.randint(0, 2, (1,)).item()  # 0=clockwise, 1=ccw\n",
    "\n",
    "    r = a + b * t\n",
    "    if direction == 0:\n",
    "        x = r * torch.cos(t)\n",
    "        y = r * torch.sin(t)\n",
    "    else:\n",
    "        x = -r * torch.cos(t)\n",
    "        y = r * torch.sin(t)\n",
    "\n",
    "    x += torch.randn_like(x) * 0.01\n",
    "    y += torch.randn_like(y) * 0.01\n",
    "\n",
    "    curve = torch.stack([x, y], dim=1)\n",
    "    curves.append(curve)\n",
    "    labels.append(direction)\n",
    "data, class_cond = torch.stack(curves), torch.tensor(labels).unsqueeze(-1)\n",
    "print(data.shape, class_cond.shape)\n",
    "\n",
    "class_cond[1,...,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "\n",
    "n_fft = 200\n",
    "hop_length = 10\n",
    "data = torch.randn(32, 64, 5)\n",
    "hop_length = 8\n",
    "print((data.shape[1]) // hop_length + 1)\n",
    "data = torch.permute(\n",
    "    data, (0, 2, 1)\n",
    ")  # we permute to match requirements of torchaudio.transforms.Spectrogram\n",
    "spec = T.Spectrogram(n_fft=15, hop_length=hop_length, center=True, power=None).to(data.device)\n",
    "transformed_data = spec(data)\n",
    "transformed_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
